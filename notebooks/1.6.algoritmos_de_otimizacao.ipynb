{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 Algoritmos de Otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No último notebook, nós programos nossa primeira rede neural. Além disso, vimos também a fórmula de atualização dos pesos. Se você não lembra, os pesos e os bias foram atualizados da seguinte forma:\n",
    "\n",
    "$$w_i = w_i - \\lambda * \\partial w $$\n",
    "\n",
    "$$b_i = b_i - \\lambda * \\partial b$$\n",
    "\n",
    "Mas, você já parou pra pensar da onde vêm essas fórmulas? Além disso, será que existem melhores formas de atualizar os pesos? É isso que vamos ver nesse notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fórmula que vimos acima, representa o **Gradiente Estocástico de Descida.** E o que significam esses termos todos? Vamos ver:\n",
    "\n",
    "- **Estocástico**: significa que os pesos são atualizados individualmente. Isto é, nós vamos passar uma amostra pro vez pra rede, que vai calcular o erro e, então, atualizar os pesos. Quando a atualização de pesos é feita para todas as amostras de uma vez, temos o **Gradiente Descendente** apenas. Da mesma forma, quando utilizamos mini-batchs, temos o **Mini-batch Gradient Descent**.\n",
    "- **Gradiente**: na matemática, o gradiente é nada mais nada menos que um vetor de derivadas. Por exemplo, se você tem duas variáveis $x$ e $y$ e calcula os gradientes $\\partial x$ $\\partial y$, o (*vetor*) gradiente será $[\\partial x, \\partial y]$.\n",
    "- **Descendente**: para quem não lembra, a derivada de uma função nos diz se a função cresce ou decresce naquele determina ponto. Como o objetivo das redes neurais é sempre diminuir um função de custo (usando derivadas), nós iremos pegar o negativo dessa derivada - por isso o sinal de menos na fórmula de atualização dos pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Momentum (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://cdn-images-1.medium.com/max/1600/1*SjtKOauOXFVjWRR7iCtHiA.gif' width=400>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
