{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Introdução a Redes Neurais: como aprendem?\n",
    "\n",
    "Nesta seção iremos introduzir o algoritmo responsável pelo aprendizado das redes neurais chamado [Gradiente Descendente](https://pt.wikipedia.org/wiki/M%C3%A9todo_do_gradiente).\n",
    "\n",
    "Para tal vamos apresentar problemas clássicos de aprendizado de máquina e implementar algoritmos clássicos de aprendizado de máquina que utilizam Gradiente Descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matemática + manipulação de vetores\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# \"Fixar\" números aleatórios a serem gerados\n",
    "np.random.seed(0)\n",
    "\n",
    "# Trabalhar com os dados\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utilidades\n",
    "import utils\n",
    "\n",
    "np.seterr(all='raise')\n",
    "\n",
    "# Recarregar automaticamente dependências caso elas mudem\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema 1: [regressão linear simples](https://pt.wikipedia.org/wiki/Regress%C3%A3o_linear_simples)\n",
    "\n",
    "\n",
    "**Problema**: Suponha que há n pontos de dados {xi, yi}, em que i = [1, 2, …, n]. O objetivo é encontrar a equação da reta $Y = X * a + b$ que proporcionaria o \"melhor\" ajuste para os dados.\n",
    "\n",
    "**Exemplo**: imaginemos que xi é a temperatura em um certo dia e yi são quantos picolés são vendidos naquele dia... queremos saber como a mudança de temperatura influencia a venda de sorvetes. Vamos imaginar que esses valores se relacionam de maneira linear, isto é, existe uma equação que responde nossa pergunta, que é do tipo:\n",
    "$numSorvetesVendidosNoDia = temperaturaNoDia * a + b$. Queremos encontrar `a` e `b`.\n",
    "\n",
    "A pergunta é: como encontrar `a` e `b`?\n",
    "\n",
    "Vamos tentar algumas ideias!\n",
    "\n",
    "### Gerando dados sintéticos\n",
    "\n",
    "Pegando o exemplo, do picolé... Espera-se que quanto mais alta a temperatura mais sorvetes sejam vendidos, isto é, esperamos que quando X cresça Y também cresça, digamos que a equação é a seguinte:\n",
    "\n",
    "$Y = 70 * X + 15 + erro$\n",
    "\n",
    "Perceba que adicionaremos também um erro a equação, por que? No mundo real dificilmente X e Y irão estar relacionados de maneira perfeitamente linear, já que podem existir erros de medição ou outros motivos podem interferir no valor de Y. Por exemplo, pode ser que esteja muito quente porém aconteça um problema de distribuição de sorvetes ou esteja muito frio mas esteja acontecendo um festival de sorvetes na cidade... Enfim, o mundo é complicado!\n",
    "\n",
    "> PS: poderíamos ter escolhido qualquer valor para a e b. Escolhemos 70 e 15 de forma arbitrária."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://www.maxpixel.net/static/photo/1x/Palette-Delicious-Coco-Summer-Picole-Gastronomy-2999877.jpg\" width=\"400\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# número de dados sintéticos gerados\n",
    "N = 200\n",
    "\n",
    "# controla o erro\n",
    "STD_DEV = 170\n",
    "\n",
    "def random_error(size, mu=0, std_dev=0.5):\n",
    "    return np.random.normal(mu, std_dev, size)\n",
    "\n",
    "def add_batch_dim(tensor):\n",
    "    if len(tensor.shape) == 1:\n",
    "        return np.expand_dims(tensor, axis=1)\n",
    "    else:\n",
    "        return tensor\n",
    "\n",
    "def remove_batch_dim(tensor):\n",
    "    return np.squeeze(tensor, axis=1)\n",
    "    \n",
    "def generate_x(size, use_batch_dim=True, scale=40):\n",
    "    x = np.random.rand(size) * scale\n",
    "    if use_batch_dim:\n",
    "        x = add_batch_dim(x)\n",
    "    return x\n",
    "\n",
    "def plot_line(x, y, style='-b'):\n",
    "    x, y = remove_batch_dim(x), remove_batch_dim(y)\n",
    "    return plt.plot([min(x), max(x)], [min(y), max(y)], style)\n",
    "\n",
    "def generate_f(x, a=70, b=15, error_std_dev=0.5, use_batch_dim=True):\n",
    "    y = a * x + b + random_error(x.shape, std_dev=error_std_dev)\n",
    "    if use_batch_dim:\n",
    "        y = add_batch_dim(y)\n",
    "    return y\n",
    "\n",
    "# gera valores aleatórios para x\n",
    "synt_x = generate_x(N)\n",
    "\n",
    "# gera a funcão: Y = 70 * X + 15 + erro\n",
    "synt_y = generate_f(synt_x, a=70, b=15, error_std_dev=STD_DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(synt_x, synt_y, 'ro', alpha=0.4)\n",
    "plt.xlabel(\"Temperatura\")\n",
    "plt.ylabel(\"Número de sorvetes vendidos\")\n",
    "plot_line(synt_x, synt_x * 70 + 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No gráfico podemos ver que: quanto mais quente -> mais sorventes são vedidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, layers=[1], input_size=1, activations=[None]):\n",
    "        assert len(layers) == len(activations)\n",
    "        self.input_size = input_size\n",
    "        self.layers = layers\n",
    "        self.activations, self._act_devs = self.get_act(activations)\n",
    "        \n",
    "        self.weights, self.biases = self.define_params()\n",
    "        self._current_batch = []\n",
    "        \n",
    "    def get_act(self, act_names):\n",
    "        def _no_act(x):\n",
    "            return x\n",
    "        def _dev_no_act(x):\n",
    "            return np.ones(x.shape)\n",
    "\n",
    "        def _sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        def _dev_sigmoid(x):\n",
    "            return x * (1 - x)\n",
    "        \n",
    "        def _relu(x):\n",
    "            return np.maximum(1e-15, x)\n",
    "        \n",
    "        def _dev_relu(x):\n",
    "            return (x > 0) * 1.0\n",
    "        \n",
    "        activations = []\n",
    "        act_devs = []\n",
    "        for act_name in act_names:\n",
    "            if act_name is None:\n",
    "                act, dev_act = _no_act, _dev_no_act\n",
    "            elif act_name == 'sigmoid':\n",
    "                act, dev_act = _sigmoid, _dev_sigmoid\n",
    "            elif act_name == 'relu':\n",
    "                act, dev_act = _relu, _dev_relu\n",
    "            else:\n",
    "                raise ValueError('Activation function is not valid: %s' % act_name)\n",
    "            \n",
    "            activations.append(act)\n",
    "            act_devs.append(dev_act)\n",
    "        return activations, act_devs\n",
    "    \n",
    "\n",
    "    def define_params(self):\n",
    "        '''He-et-all initialization'''\n",
    "        weights = []\n",
    "        biases = []\n",
    "        for i, (in_dim, out_dim) in enumerate(zip([self.input_size] + self.layers, self.layers)):\n",
    "            weights.append(np.random.randn(in_dim, out_dim) * np.sqrt(2/in_dim))\n",
    "            biases.append(np.random.randn(out_dim) * np.sqrt(2/in_dim))           \n",
    "            print('Weight %d shape =' % i, weights[i].shape)\n",
    "            print('Bias %d shape =' % i, biases[i].shape)\n",
    "            \n",
    "        return weights, biases\n",
    "\n",
    "\n",
    "    def update_params(self, gradients, learning_rate=0.1):\n",
    "        assert len(gradients) == len(self.weights), (len(gradients), len(self.weights))\n",
    "        assert len(gradients) == len(self.biases), (len(gradients), len(self.biases))\n",
    "        \n",
    "        for i, grad in enumerate(gradients[::-1]):\n",
    "            assert grad['weights'].shape == self.weights[i].shape\n",
    "            self.weights[i] -= learning_rate * grad['weights']\n",
    "            self.biases[i] -= learning_rate * grad['biases']\n",
    "\n",
    "    \n",
    "    def run_batch(self, batch):\n",
    "        self._current_batch = [batch]\n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            output = np.dot(self._current_batch[-1], w) + b\n",
    "            output = self.activations[i](output)\n",
    "            self._current_batch.append(output)\n",
    "        \n",
    "        self._current_batch = self._current_batch[::-1]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, learning_rate = 0.01, loss_name='l2',\n",
    "                 print_mod=1000, verbose=True):\n",
    "        \n",
    "        def _accuracy(pred_y, real_y):\n",
    "            print(pred_y, real_y)\n",
    "            p = np.argmax(self.softmax(pred_y), axis=1)\n",
    "            return np.sum(p == real_y) / len(pred_y)\n",
    "            \n",
    "        \n",
    "        self.model = model\n",
    "        self.loss_name = loss_name\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss, self.loss_dev = self._define_loss()\n",
    "        \n",
    "        self.train_step = 0\n",
    "        self.eval_steps = []\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.print_mod = print_mod\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.eval_losses = []\n",
    "        \n",
    "        self._metrics = {\n",
    "            'accuracy': _accuracy\n",
    "        }\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exps = np.exp(x)\n",
    "        return (exps / np.sum(exps, axis=1, keepdims=True))\n",
    "        \n",
    "    def _define_loss(self):\n",
    "        def _l2(pred_y, real_y):\n",
    "            n = len(pred_y)\n",
    "            return (1.0/2) * (1.0/n) * np.sum(np.power(pred_y - real_y, 2))\n",
    "        \n",
    "        def _l2_dev(pred_y, real_y):\n",
    "            n = len(pred_y)\n",
    "            return (pred_y - real_y) * (1.0/n)\n",
    "        \n",
    "        def _cross_entropy(pred_y, real_y):\n",
    "            m = real_y.shape[0]\n",
    "            p = self.softmax(pred_y)\n",
    "            # We use multidimensional array indexing to extract \n",
    "            # softmax probability of the correct label for each sample.\n",
    "            # Refer to https://docs.scipy.org/doc/numpy/user/basics.indexing.html#indexing-multi-dimensional-arrays for understanding multidimensional array indexing.\n",
    "            log_likelihood = -np.log(p[range(m), real_y.astype(int)])\n",
    "            loss = np.sum(log_likelihood) / m\n",
    "            return loss\n",
    "    \n",
    "        \n",
    "        def _cross_entropy_dev(pred_y, real_y):\n",
    "            m = real_y.shape[0]\n",
    "            grad = self.softmax(pred_y)\n",
    "            grad[range(m), real_y.astype(int)] -= 1\n",
    "            grad = grad / m\n",
    "            return grad\n",
    "\n",
    "        if self.loss_name == 'l2':\n",
    "            return _l2, _l2_dev\n",
    "        elif self.loss_name == 'cross-entropy':\n",
    "            return _cross_entropy, _cross_entropy_dev\n",
    "        else:\n",
    "            raise ValueError('Invalid loss name: %s' % self.loss_name)\n",
    "\n",
    "\n",
    "    def train(self, batch_x, batch_y):\n",
    "        self.train_step += 1\n",
    "        \n",
    "        # run feed forward network\n",
    "        pred_y = self.model.run_batch(batch_x)\n",
    "        # save loss\n",
    "        self.train_losses.append(self.loss(pred_y, batch_y))\n",
    "        # get gradients\n",
    "        grads = self.generate_gradients(pred_y, batch_y, batch_x)\n",
    "        # update parameters\n",
    "        self.model.update_params(grads, self.learning_rate)\n",
    "\n",
    "        if self.verbose and (self.train_step - 1) % self.print_mod == 0:\n",
    "            print('Loss: %.4f for step %d' % (self.train_losses[-1], self.train_step))\n",
    "\n",
    "\n",
    "    def eval(self, batch_x, batch_y, metrics=[]):\n",
    "        # run feed forward network\n",
    "        pred_y = self.model.run_batch(batch_x)\n",
    "        # loss\n",
    "        loss = self.loss(pred_y, batch_y)\n",
    "        self.eval_losses.append(loss)\n",
    "        # metrics\n",
    "        res_metrics = []\n",
    "        for m in metrics:\n",
    "            if m in self._metrics:\n",
    "                res_metrics.append(self._metrics[m](pred_y, batch_y))\n",
    "            else:\n",
    "                raise ValueError('Invalid metric: %s' % m)\n",
    "        \n",
    "        self.eval_steps.append(self.train_step)\n",
    "            \n",
    "        return loss, res_metrics\n",
    "\n",
    "    \n",
    "    def plot_losses(self):\n",
    "        if len(self.eval_losses) > 0:\n",
    "            plt.title('Train Loss: %.4f | Test Loss: %.4f for step %d' % (self.train_losses[-1], self.eval_losses[-1], self.train_step))\n",
    "        else:\n",
    "            plt.title('Train Loss: %.4f for step %d' % (self.train_losses[-1], self.train_step))    \n",
    "        plt.plot([i for i in range(self.train_step)], self.train_losses)\n",
    "        plt.plot([i for i in self.eval_steps], self.eval_losses)\n",
    "        \n",
    "        \n",
    "    def generate_gradients(self, pred_y, real_y, data_x):\n",
    "        grad = []\n",
    "        input_size = pred_y.shape[0]\n",
    "        j = len(self.model.activations) - 1\n",
    "        k = len(self.model.weights) - 1\n",
    "        dly = self.loss_dev(pred_y, real_y) * self.model._act_devs[j](self.model._current_batch[0])\n",
    "        dlx = np.dot(dly, self.model.weights[k].T)\n",
    "\n",
    "        for i, (w, b) in enumerate(zip(self.model.weights[::-1], self.model.biases[::-1])):\n",
    "            dlw = np.dot(self.model._current_batch[i+1].T, dly)\n",
    "            dlb = np.sum(dly)\n",
    "            # print('weight:', w.shape, 'bias:', b.shape)\n",
    "            # print('dlw:', dlw.shape, 'dlb:', dlb.shape)\n",
    "            # print('dly:', dly.shape, 'dlx:', dlx.shape)\n",
    "            grad.append({\n",
    "                'weights': dlw,\n",
    "                'biases': dlb\n",
    "            })\n",
    "            \n",
    "            j -= 1\n",
    "            k -= 1\n",
    "            if i != len(self.model.weights)-1:\n",
    "                dly = dlx * self.model._act_devs[j](self.model._current_batch[i+1])\n",
    "                dlx = np.dot(dly, self.model.weights[k].T)\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "##### L2 loss with 1 layer, no activation\n",
    "\n",
    "**Loss**\n",
    "\n",
    "$$L = 1/2 * 1/n * \\sum{(y_i - ŷ_i)^{2}}$$\n",
    "$$L = 1/2 * 1/n * \\sum{(y_i - w_i * x_i + b_i)^{2}}$$\n",
    "\n",
    "**Gradients**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_i} = 1/2 * 1/n * 2 * \\sum{(y_i - ŷ_i)} * \\frac{\\partial {ŷ_i}}{\\partial w_i} $$\n",
    "$$\\frac{\\partial L}{\\partial w_i} = 1/n * \\sum{(y_i - ŷ_i)} * x_i$$\n",
    "\n",
    "---\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b_i} = 1/2 * 1/n * 2 * \\sum{(y_i - ŷ_i)} * \\frac{\\partial {ŷ_i}}{\\partial b_i} $$\n",
    "$$\\frac{\\partial L}{\\partial b_i} = 1/n * \\sum{(y_i - ŷ_i)} * 1$$\n",
    "\n",
    "\n",
    "##### L2 loss with 2 layers, relu activation in the hidden layer\n",
    "\n",
    "**Loss**\n",
    "\n",
    "$$L = 1/2 * 1/n * \\sum{(y_i - ŷ_i)^{2}}$$\n",
    "$$L = 1/2 * 1/n * \\sum{(y_i - (w_j * x_j + b_j))^{2}}$$\n",
    "$$x_j = relu(w_i * x_i + b_i)$$\n",
    "\n",
    "\n",
    "**Gradients**\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_i} = 1/n * \\sum{(y_i - ŷ_i)} * x_j $$\n",
    "$$\\frac{\\partial L}{\\partial b_i} = 1/n * \\sum{(y_i - ŷ_i)} * 1$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial w_j} = 1/n * \\sum{(y_i - ŷ_i)} * x_j * x_i, se relu() > 0$$\n",
    "$$\\frac{\\partial L}{\\partial b_j} = 1/n * \\sum{(y_i - ŷ_i)} * x_j, se relu() > 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork()\n",
    "t = Trainer(nn, verbose=False)\n",
    "for i in range(100000):\n",
    "    t.train(synt_x, synt_y)\n",
    "\n",
    "t.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparando com a realidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parâmetros aprendidos:')\n",
    "print('pesos:', nn.weights)\n",
    "print('bias:', nn.biases)\n",
    "print('Função que modela os dados: 7 * X + 15')\n",
    "plot_line(synt_x, nn.run_batch(synt_x), '--r')\n",
    "plot_line(synt_x, synt_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ⚠️ **Cuidado: não confunda parâmetro com hiperparâmetros!** Parâmetros são o que a sua rede usa para aprender (pesos e bias), enquanto hiperparâmetros são o que você define acerca da sua rede (número de camadas, qtde. de neurônios por camada, função de ativação de cada camada, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma função um pouco mais complicada\n",
    "\n",
    "$Y = 7 * log(x) + 1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_error(size, mu=0, std_dev=0.8):\n",
    "    return np.random.normal(mu, std_dev, size)\n",
    "\n",
    "synt_x = np.random.rand(SYNT_TRAIN_SIZE)\n",
    "synt_y = np.reshape(7 * np.log(synt_x) + 1 + get_random_error(SYNT_TRAIN_SIZE), (SYNT_TRAIN_SIZE, 1))\n",
    "\n",
    "synt_x = np.reshape(synt_x, (SYNT_TRAIN_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(synt_x, synt_y, 'ro', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(layers=[10, 1], activations=['sigmoid', None])\n",
    "t = Trainer(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    t.train(synt_x, synt_y)\n",
    "\n",
    "t.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parâmetros aprendidos:')\n",
    "print('pesos:', nn.weights)\n",
    "print('bias:', nn.biases)\n",
    "print('Função que modela os dados: 7 * X + 15')\n",
    "plt.plot(synt_x, nn.run_batch(synt_x), 'or', alpha=0.3)\n",
    "plt.plot(synt_x, synt_y, 'og', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E se os dados forem não lineares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "xor_y = np.array([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(layers=[10, 2], input_size=2, activations=['relu', None])\n",
    "t = Trainer(nn, verbose=False)\n",
    "for i in range(100000):\n",
    "    t.train(xor_x, xor_y)\n",
    "\n",
    "t.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xor_x, nn.run_batch(xor_x), 'bo', xor_x, xor_y, 'ro', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(layers=[10, 1], input_size=2, activations=[None, None])\n",
    "t = Trainer(nn, verbose=False)\n",
    "for i in range(100000):\n",
    "    t.train(xor_x, xor_y)\n",
    "\n",
    "t.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(xor_x, nn.run_batch(xor_x), 'bo', xor_x, xor_y, 'ro', alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados Iris\n",
    "\n",
    "A base de dados Iris foi publicada originalmente no [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/iris).\n",
    "\n",
    "Uma das bases de dados mais conhecidas. É uma pequena base contendo informações sobre plantas de 3 diferentes espécies (setosa, versicolour e virginica). É bastante utilizada para classificação das espécies\n",
    "\n",
    "* Atributos:\n",
    "    1. sepal length in cm \n",
    "    2. sepal width in cm \n",
    "    3. petal length in cm \n",
    "    4. petal width in cm \n",
    "5. Classes: \n",
    "    0. Iris Setosa \n",
    "    1. Iris Versicolour \n",
    "    2. Iris Virginica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar iris dataset\n",
    "iris = fetch_mldata('iris')\n",
    "# np.c_ concatena as features e targets do dataset\n",
    "iris_data = pd.DataFrame(data=np.c_[iris['data'], iris['target']],\n",
    "                         columns=['x0', 'x1', 'x2', 'x3', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris_data.drop(['target'], axis=1).diff().hist(color='k', alpha=0.5, bins=10, figsize=(4, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(x, y, batch_size=True):\n",
    "    idx = np.random.permutation(len(x))\n",
    "    x = x[idx]\n",
    "    y = y[idx]\n",
    "    \n",
    "    for i in range(0, len(x)-batch_size-1, batch_size):\n",
    "        batch_x = x[i:i+batch_size]\n",
    "        batch_y = y[i:i+batch_size]\n",
    "        yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(layers=[10, 4], input_size=4, activations=['relu', None])\n",
    "t = Trainer(nn, verbose=False, loss_name='cross-entropy')\n",
    "for i in range(1000):\n",
    "    for batch_x, batch_y in batches(x, y, 16):\n",
    "        t.train(batch_x, batch_y)\n",
    "    if i % 10 == 0:\n",
    "        loss, metrics = t.eval(x_test, y_test, metrics=['accuracy'])\n",
    "        print('Test loss = %.5f, accuracy %.5f' % (loss, metrics[0]))\n",
    "\n",
    "t.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mnist.data / np.max(mnist.data)\n",
    "y = mnist.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(layers=[512, 256, 10], input_size=784, activations=['relu', 'relu', None])\n",
    "t = Trainer(nn, verbose=False, loss_name='cross-entropy', learning_rate=0.001)\n",
    "for i in range(20):\n",
    "    for batch_x, batch_y in batches(x, y, 64):\n",
    "        t.train(batch_x, batch_y)\n",
    "    if i % 1 == 0:\n",
    "        loss, metrics = t.eval(x_test, y_test, metrics=['accuracy'])\n",
    "        print('Test loss = %.5f, accuracy %.5f' % (loss, metrics[0]))\n",
    "\n",
    "t.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "* [Blog do Matheus Facure sobre Gradiente Descendente (10/10)](https://matheusfacure.github.io/2017/02/20/MQO-Gradiente-Descendente/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
