
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="ipynb_website:version" content="0.9.6" />
<meta name="viewport" content="width=device-width, initial-scale=1" />

<link rel="stylesheet" type="text/css" href="../css/jt.css">
<link rel="stylesheet" type="text/css" href="../css/readable.css">
<link rel="stylesheet" type="text/css" href="../css/toc2.css">

<link href="../site_libs/jqueryui-1.11.4/jquery-ui.css">
<link rel="stylesheet" href="../site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<link rel="stylesheet" href="../site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jqueryui/1.9.1/jquery-ui.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="../site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>

<link rel="stylesheet"
      href="../site_libs/highlightjs-1.1/textmate.css"
      type="text/css" />

<script src="../site_libs/highlightjs-1.1/highlight.js"></script>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>

<script src="../js/doc_toc.js"></script>
<script src="../js/docs.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX", "output/HTML-CSS"],
        tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
        },
        "HTML-CSS": {
            preferredFont: "TeX",
            availableFonts: ["TeX"],
            styles: {
                scale: 110,
                ".MathJax_Display": {
                    "font-size": "110%",
                }
            }
        }
    });
</script>
<script>
function filterDataFrame(id) {
    var input = document.getElementById("search_" + id);
    var filter = input.value.toUpperCase();
    var table = document.getElementById("dataframe_" + id);
    var tr = table.getElementsByTagName("tr");
    // Loop through all table rows, and hide those who don't match the search query
    for (var i = 1; i < tr.length; i++) {
        for (var j = 0; j < tr[i].cells.length; ++j) {
            var matched = false;
            if (tr[i].cells[j].innerHTML.toUpperCase().indexOf(filter) != -1) {
                tr[i].style.display = "";
                matched = true
                break;
            }
            if (!matched)
                tr[i].style.display = "none";
        }
    }
}
function sortDataFrame(id, n, dtype) {
    var table = document.getElementById("dataframe_" + id);
    var tb = table.tBodies[0]; // use `<tbody>` to ignore `<thead>` and `<tfoot>` rows
    var tr = Array.prototype.slice.call(tb.rows, 0); // put rows into array
    if (dtype === 'numeric') {
        var fn = function(a, b) { 
            return parseFloat(a.cells[n].textContent) <= parseFloat(b.cells[n].textContent) ? -1 : 1;
        }
    } else {
        var fn = function(a, b) {
            var c = a.cells[n].textContent.trim().localeCompare(b.cells[n].textContent.trim()); 
            return c > 0 ? 1 : (c < 0 ? -1 : 0) }
    }
    var isSorted = function(array, fn) {
        if (array.length < 2)
            return 1;
        var direction = fn(array[0], array[1]); 
        for (var i = 1; i < array.length - 1; ++i) {
            var d = fn(array[i], array[i+1]);
            if (d == 0)
                continue;
            else if (direction == 0)
                direction = d;
            else if (direction != d)
                return 0;
            }
        return direction;
    }
    var sorted = isSorted(tr, fn);
    if (sorted == 1 || sorted == -1) {
        // if sorted already, reverse it
        for(var i = tr.length - 1; i >= 0; --i)
            tb.appendChild(tr[i]); // append each row in order
    } else {
        tr = tr.sort(fn);
        for(var i = 0; i < tr.length; ++i)
            tb.appendChild(tr[i]); // append each row in order
    }
}
</script>

<script>
$( document ).ready(function(){
            var cfg={'threshold':3,     // depth of toc (number of levels)
             'number_sections': false,
             'toc_cell': false,          // useless here
             'toc_window_display': true, // display the toc window
             "toc_section_display": "block", // display toc contents in the window
             'sideBar':true,       // sidebar or floating window
             'navigate_menu':false       // navigation menu (only in liveNotebook -- do not change)
            }
            var st={};                  // some variables used in the script
            st.rendering_toc_cell = false;
            st.config_loaded = false;
            st.extension_initialized=false;
            st.nbcontainer_marginleft = $('#notebook-container').css('margin-left')
            st.nbcontainer_marginright = $('#notebook-container').css('margin-right')
            st.nbcontainer_width = $('#notebook-container').css('width')
            st.oldTocHeight = undefined
            st.cell_toc = undefined;
            st.toc_index=0;
            // fire the main function with these parameters
            table_of_contents(cfg, st);
            var file=notebooksDict[$("h1:first").attr("id")];
            $("#toc-level0 a").css("color","#126dce");
            $('a[href="#'+$("h1:first").attr("id")+'"]').hide()
            var docs=notebooksArray;
            var docs_map=notebooksArrayMap;
            var pos=notebooksArray.indexOf(file);
            for (var a=pos;a>=0;a--){
                  $('<li><a href="'+docs[a]+'.html"><font color="#073642"><b>'+docs_map[docs[a]].replace(/_/g," ")+'</b></font></a></li>').insertBefore("#toc-level0 li:eq(0)");
            }
            $('a[href="'+file+'.html'+'"]').css("color","#126dce");
            for (var a=pos+1;a<docs.length;a++){
                  $(".toc #toc-level0").append('<li><a href="'+docs[a]+'.html"><font color="#073642"><b>'+docs_map[docs[a]].replace(/_/g," ")+'</b></font></a></li>');
            }
            // $("#toc-header").hide(); // comment out because it prevents search bar from displaying
    });
</script>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');
  // mark it active
  menuAnchor.parent().addClass('active');
  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>
<div class="container-fluid main-container">
<!-- tabsets -->
<script src="../site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>



<title>Codando Deep Learning</title>

<style type = "text/css">
body {
  
  padding-top: 66px;
  padding-bottom: 40px;
}
</style>
</head>

<body>
<div tabindex="-1" id="notebook" class="border-box-sizing">
<div class="container" id="notebook-container">

<!-- code folding -->

<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">Codando Deep Learning</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
<li>
  <a href="../notebooks.html">Notebooks</a>
</li>
        
      </ul>
        
<ul class="nav navbar-nav navbar-right">
<li>
   <a href="http://github.com/mari-linhares/codando-deep-learning"> Github </a>
</li>
</ul>
        
      </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Depend&#234;ncias">Depend&#234;ncias<a class="anchor-link" href="#Depend&#234;ncias">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Gráficos</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Matemática + manipualação de vetores</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># &quot;Fixar&quot; números aleatórios a serem gerados</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Trabalhar com os dados</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.mldata</span> <span class="k">import</span> <span class="n">fetch_mldata</span>

<span class="c1"># Utilidades</span>
<span class="kn">import</span> <span class="nn">utils</span>

<span class="c1"># Recarregar automaticamente dependências caso elas mudem</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introdu&#231;&#227;o-&#224;-Redes-Neurais">Introdu&#231;&#227;o &#224; Redes Neurais<a class="anchor-link" href="#Introdu&#231;&#227;o-&#224;-Redes-Neurais">&#182;</a></h2><p>Esse conteúdo é bastante inspirado no <a href="https://github.com/iamtrask/Grokking-Deep-Learning">Capítulo 3</a> de Grokking Deep Learning.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Redes neurais podem ser vistas de maneira bastante simplificadas como <strong>funções matemáticas</strong>. De fato, se eu tivesse que definir redes neurais com apenas uma frase, seria:</p>
<blockquote><p>"Redes Neurais são <em>aproximadores de função</em>"</p>
</blockquote>
<p>Desse modo, similar à funções, as redes neurais recebem uma ou mais entradas e a mapeiam para uma ou mais saídas. Aqui, mapear = realizar computação.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Falando em Deep Learning, essas entradas são normalmente <strong>tensores</strong>, isto é, vetores de diferentes dimensões. De maneira matemática, você pode pensar em tensores da seguinte forma:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://www.kdnuggets.com/wp-content/uploads/scalar-vector-matrix-tensor.jpg" alt="">
Imagem de: <a href="https://www.kdnuggets.com/2018/05/wtf-tensor.html">https://www.kdnuggets.com/2018/05/wtf-tensor.html</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Já os matemáticos que gostam de cachorros, preferem pensar em tensores da seguinte forma:</p>
<p><img src="https://pbs.twimg.com/media/CvUaME-VIAACHLb.jpg" alt="">
Imagem de: <a href="https://pbs.twimg.com/media/CvUaME-VIAACHLb.jpg">https://pbs.twimg.com/media/CvUaME-VIAACHLb.jpg</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Na prática, um <strong>scalar</strong> é apenas um valor (0-dimensional); um <strong>vetor</strong> é um array de scalares (uni-dimensional); uma <strong>matriz</strong> é um array de vetores (bi-dimensional); e um <strong>tensor</strong> é qualquer vetor com N-dimensões (por exemplo, um cubo é um tensor de 3 dimensões). Vale salientar que, tecnicamente, o conceito de tensor engloba todos eles. Porém, na prática, chamamos de tensores os vetores com 3 ou mais dimensões. Veja <a href="https://www.youtube.com/watch?v=f5liqUk0ZTw"><strong>esse vídeo</strong></a> para mais detalhes.</p>
<p>Ainda pensando dessa forma, poderíamos imaginar um tensor 4-dimensional como um <strong>array de cubos</strong>; um tensor 5-dimensional seria uma <strong>matriz de cubos</strong>; um tensor 6-dimensional seria um <strong>cubo de cubos</strong>, e assim por diante...</p>
<p><img align='center' src='https://media3.giphy.com/media/xT0xeJpnrWC4XWblEk/giphy.gif'></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Hist&#243;ria-das-Redes-Neurais">Hist&#243;ria das Redes Neurais<a class="anchor-link" href="#Hist&#243;ria-das-Redes-Neurais">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A história das redes neurais é curiosa, engraçada e triste ao mesmo tempo.</p>
<p>Certo dia, em 1958, um certo cientista nova-yorkino, inspirado pelo trabalho de seus colegas que estudavam sobre o cérebro humano, terminou de projetar um algoritmo que conseguia aprender sozinho a resolver problemas simples. Nascia ali, o <strong>Perceptron</strong>. Em sua estrutura básica, o Perceptron é formado por 3 partes:</p>
<p><img align='center' src='https://github.com/arnaldog12/Manual-Pratico-Deep-Learning/raw/2d4adc1a095b815d523cf1d84ba3422c8c30ae1d/images/perceptron.png' width=400></p>
<ul>
<li><strong>entradas</strong> $x_1,...,x_D$: representam os atributos dos seus dados com dimensionalidade $D$. O Perceptron aceita qualquer tamanho de entrada, porém a saída é sempre apenas um valor.</li>
<li><strong>junção aditiva</strong> $\sum$: também chamada de <em>função agregadora</em>, nada mais é que a soma ponderada das entradas com os <strong>pesos</strong> ($w_1,...,w_D)$. Em geral, o resultado é somado com um <strong>bias</strong> $b$, responsável por deslocar o resultado do somatório. A junção aditiva é descrita pela seguinte fórmula:</li>
</ul>
$$\sum_i^D{x_iw_i} + b$$<ul>
<li><strong>função de ativação</strong> $f$: utilizada para mapear o resultado da junção aditiva em uma saída esperada. No caso do Perceptron, ela é a função <em>step</em> (também conhecida como <em>função degrau</em>) para mapear a saída em um valor discreto (0 ou 1):</li>
</ul>
$$f = \begin{cases}1 &amp; se \ wx+b &gt; 0\\0 &amp; caso \ contr\acute ario\end{cases}$$<p>A ideia inicial do Perceptron, na verdade, era ser uma máquina ao invés de um programa. E foi o que aconteceu. Utilizando o poderosíssimo <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a> que fazia 12 mil adições por segundo (só para você ter uma noção, um iPhone 7 faz 300 bilhões) os caras construíram uma máquina denominada <strong>Mark I Perceptron</strong>.</p>
<p><img align='center' src='images/mark_i.jpg' width=600></p>
<p>A ideia do Mark I Perceptron era que, para uma dada imagem de entrada, a máquina deveria aprender sozinha a classificar a saída em 0 ou 1. Mas, calma, nem imagens existiam naquela época! Então, como projetaram isso? Os cientistas na época conectaram 400 foto-células a entrada do Mark I para simular uma imagem 20x20 (um pouco maior talvez do que as letras desse texto). E para permitir a calibração da máquina, cada entrada dessa era conectada a um potenciômetro (que simulavam os pesos) que eram ajustados automaticamente por motores elétricos para mapear as entradas na saída final 0 ou 1.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MyFirstNeuralNetwork</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span> <span class="o">=</span> <span class="n">weights</span>
    
    <span class="k">def</span> <span class="nf">function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_input</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_activation_function</span><span class="p">(</span><span class="n">_input</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_weights</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">_activation_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nn</span> <span class="o">=</span> <span class="n">MyFirstNeuralNetwork</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<hr>
&copy; 2019 Marianne Linhares, Arnaldo Gualberto

</div>
</div>
</body>
</html>
